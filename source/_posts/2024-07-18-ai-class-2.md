---
title: “第二课堂”AI实践 随堂笔记（二）：Python环境配置及基础学习
date: 2024-07-18 21:00:35
tags: [“第二课堂”AI实践]
---

# 零、课程与笔记相关信息

- [本节课的课程回放（B站）](https://www.bilibili.com/video/BV1WKbXeDEth/)
- 本笔记基于上述课程回放进行记录与补充完善，可能与实际直播略有出入。
- 本笔记部分内容摘自视频并手动码字，可能产生些许错别字及谐音字。

基于上述原因，请各位读者批评指正，向作者提出宝贵意见与建议，笔者感激不尽。

# 一、课程目标

学习 Python 语言中 `pandas` 库的基本使用方法，并使用该库处理一些简单的数据集，达成所需的目的。

# 二、课堂内容

## 1. 课程前言

这门课程得主要目的是通过真实的数据，以实战的方式了解数据分析的流程和熟悉数据分析 Python 的基本操作。知道了课程的目的之后，我们接下来我们要正式的开始数据分析的实战教学，完成 Kaggle 上泰坦尼克的任务，实战数据分析全流程。

## 2. 常用 Python 库的引入方式

Python 中的库（模块）通过 `import` 语句进行引入。特别地，对于 NumPy 与 Pandas 二库，习惯分别指定别名 `np` 与 `pd`。

```python
import numpy as np
import pandas as pd
```

## 3. 使用 Pandas 从文件中加载数据

### 普通读取

`pandas` 库提供了 `read_csv` 方法以从给定的 CSV 文件中加载数据。其中文件名既可以相对路径，又可以绝对路径的形式给出。

```python
# 以相对路径的方式指定文件名并载入数据
df = pd.read_csv('train.csv')
```

```python
# 以绝对路径的方式指定文件名并载入数据
df = pd.read_csv('/home/srcres/Coding/Projects/pandas-learn/pandas_rumen/train.csv')
```

### 逐块读取

通过指定 `read_csv` 方法的 `chunksize` 参数，可实现一次读取一定条目的逐块读取方式加载数据。例如，实现一次读取 1000 条数据的逐块加载：

```python
reader = pd.read_csv('train.csv', chunksize=1000)

for i, chunk in enumerate(reader):
    print(f"----- Chunk {i} -----")
    print(chunk)
```

## 4. 更改数据集表头名称（更改列名）

### 需求

现将样例数据集中的各英文列名翻译为中文，需要使用 Pandas 提供的列名重命名功能。翻译如下表所示：

英文 | 中文
:-: | :-:
PassengerId | 乘客ID  
Survived    | 是否幸存   
Pclass      | 乘客等级(1/2/3等舱位)  
Name        | 乘客姓名  
Sex         | 性别                 
Age         | 年龄                 
SibSp       | 堂兄弟/妹个数  
Parch       | 父母与小孩个数  
Ticket      | 船票信息             
Fare        | 票价                
Cabin       | 客舱                
Embarked    | 登船港口 

### 方式一

方式一（课程给出的方式），通过指定 `read_csv` 函数的 `names` 参数，实现在加载数据集的同时就完成列名重命名操作。

```python
df = pd.read_csv('train.csv', names=['乘客ID', '是否幸存', '乘客等级(1/2/3等舱位)', '乘客姓名', '性别', '年龄', '堂兄弟/妹个数', '父母与小孩个数', '船票信息', '票价', '客舱', '登船港口'])
```

`read_csv` 有丰富的功能各异的参数，使用得当能在加载数据时完成许多预处理操作。例如，在此基础之上再指定索引 `index` 列为 `'乘客ID'`：

```python
df = pd.read_csv('train.csv', names=['乘客ID', '是否幸存', '乘客等级(1/2/3等舱位)', '乘客姓名', '性别', '年龄', '堂兄弟/妹个数', '父母与小孩个数', '船票信息', '票价', '客舱', '登船港口'], index_col='乘客ID', header=0)
```

结果如下：

{% asset_img Screenshot_20240719_164520.png %}

### 方式二

方式二（笔者给出的方式），使用 `read_csv` 正常再入数据集，之后调用 Pandas 提供的其他功能函数进行数据集的后续处理。

```python
df = pd.read_csv('train.csv')
```

载入后，先使用 `rename` 函数完成列名更名：

```python
df = df.rename(columns={
    'PassengerId': '乘客ID',
    'Survived': '是否幸存',
    'Pclass': '乘客等级(1/2/3等舱位)',
    'Name': '乘客姓名',
    'Sex': '性别',
    'Age': '年龄',
    'SibSp': '堂兄弟/妹个数',
    'Parch': '父母与小孩个数',
    'Ticket': '船票信息',
    'Fare': '票价',
    'Cabin': '客舱',
    'Embarked': '登船港口'
})
```

接着再使用 `set_index` 函数设置数据集的索引列：

```python
df = df.set_index('乘客ID')
```

最终得到与方式一相同的结果：

{% asset_img Screenshot_20240719_164654.png %}

## 5. 数据集的初步观察

### 显示数据集的摘要

使用 `info` 函数获取数据集每一列数据的摘要。

```python
df.info()
```

{% asset_img Screenshot_20240719_170109.png %}

### 显示数据集的首末行信息

使用 `head` 或 `tail` 以获取数据集的前任意行或末尾任意行的数据信息。

```python
# 显示 df 的前 10 行信息
df.head(10)
```

{% asset_img Screenshot_20240719_170502.png %}

```python
# 显示 df 的后 15 行信息
df.tail(15)
```

{% asset_img Screenshot_20240719_170520.png %}

### 数据集空值的判断

使用 `isnull` 函数判断数据集各部分是否存在空值，并一一映射为全是 `bool` 类型数据的 `DataFrame`。

例如，显示数据集 `df` 中前5行数据的空值分布情况。

```python
df.isnull().head(5)
```

{% asset_img Screenshot_20240719_171001.png %}

## 6. 数据集的保存

对数据集 `DataFrame` 调用 `to_csv` 函数以将数据集保存为指定名称的 CSV 文件。

注意文本文件的文本编码问题。由于不同操作系统的默认文本编码不同（Windows 上默认为 `GBK`，GNU/Linux 上默认为 `UTF-8`），如所保存的文件出现乱码现象，就需要通过 `to_csv` 函数的 `encoding` 参数手动指定文件编码。

例如，将 `df` 保存到 `train_chinese.csv` 文件中，并指定文本编码为 `utf-8`：

```python
df.to_csv('train_chinese.csv', encoding='utf-8')
```

## 7. 获取数据集的所有列

通过数据集 `DataFrame` 的 `columns` 属性，可以轻松地获取其所有列的名称。例如：

```python
print('\n'.join(list(df.columns)))
```

{% asset_img Screenshot_20240719_172228.png %}

## 8. 数据集的列操作

### 理论储备

要获取数据集某一列的所有值，可使用下标索引语法，给定需要进行获取的列名即可。得到的结果是 `Series` 类型的。

例如，查询 `df` 中 `'Cabin'` 一列中的所有值：

```python
df['Cabin']
```

{% asset_img Screenshot_20240719_172739.png %}

或者，也可通过点语法获取。Pandas 已将各列数据包装成为 `DataFrame` 的属性，只需访问列名对应的属性即可：

```python
df.Cabin
```

{% asset_img Screenshot_20240719_173410.png %}

> **小记**
>
> 亦可使用 `DataFrame` 的 `loc` 属性，通过筛选出对应列的数据，实现列数据的获取。
>
> ```python
> df.loc[:, 'Cabin']
> ```
>
> {% asset_img Screenshot_20240719_174639.png %}

### 实战演练

#### 需求

加载文件 `test_1.csv`，然后对比 `train.csv`，看看有哪些多出的列，然后将多出的列删除。

#### 实现

先将上述两个数据集进行加载：

```python
# train.csv 即为前文数据集对象 df，省略其加载步骤。
df_test_1 = pd.read_csv('test_1.csv')
```

接下来通过简单的算法，筛选出题目所要求的多余的列：

```python
df_cols = list(df.columns)
dup_cols = [] # 多余的列

for col in list(df_test_1.columns):
    if col not in df_cols:
        dup_cols.append(col)
```

最后使用 `drop` 函数将 `df_test_1` 中的多余列删除。务必注意指定 `axis` 参数：

```python
df_test_1 = df_test_1.drop(dup_cols, axis=1)
```

结果如下：

{% asset_img Screenshot_20240719_174229.png %}

> **小记**
>
> 亦可通过 Python 的 `del` 关键字对 `DataFrame` 的列进行删除。如上述代码：
>
> ```python
> df_test_1 = df_test_1.drop(dup_cols, axis=1)
> ```
>
> 可修改为等价代码：
>
> ```python
> for col in dup_cols:
>     del df_test_1[col]
> ```

## 9. 数据集的隐藏

`DataFrame` 中有个 `style` 属性，该属性控制 `DataFrame` 在笔记本或终端中被展示出来时的样式。通过调用 `style` 属性的 `hide` 方法，能将 `DataFrame` 中特定的部分隐藏起来，从而不会在笔记本或终端中被展示出来。

例如，将 `df_test_1` 中 `'PassengerId'`、`'Name'`、`'Age'`、`'Ticket'` 这些列隐藏起来：

```python
df_test_1.style.hide(['PassengerId', 'Name', 'Age', 'Ticket'], axis=1)
```

结果如下：（~~此处我的 IDE 抽风，不显示结果，应该是 IDE 的 bug = =，被迫切换网页版的 Jupyter Notebook。~~）

{% asset_img Screenshot_20240719_180119.png %}

> **注意**
>
> 此处知识点，课程所介绍的隐藏数据方式有误。`drop` 函数与 `del` 关键字相同，均是删除 `DataFrame` 中的数据，而**非**隐藏数据。要隐藏数据不被展示出来，而不破坏原有的数据结构，只能通过操作 `style` 属性来实现，如上所述。
>
> {% asset_img Screenshot_20240719_180616.png %}

## 10. 数据集的筛选

Pandas 支持多种方式从数据集中筛选符合给定指定的数据。

### 简单的数据筛选

#### 题目一

题目一：从数据集 `df` 中筛选出 `'Age'` 在10岁以下的乘客信息。

在 Pandas 中，我们可以使用 `DataFrame` 的 `loc` 属性来实现，并传入我们的查询条件：

```python
df.loc[df['Age'] < 10, :]
```

观察所得数据，其 `'Age'` 值均小于10，符合我们的预期。

{% asset_img Screenshot_20240719_193452.png %}

> **小记**
>
> 亦可不使用 `loc` 属性，直接使用查询条件作为索引，效果等价。
>
> ```python
> df[df['Age'] < 10]
> ```
>
> {% asset_img Screenshot_20240719_193829.png %}

#### 题目二

题目二：以 `'Age'` 为条件，将年龄在10岁以上和50岁以下的乘客信息显示出来，并将这个数据命名为 `midage`。

在 Pandas 中，筛选条件之间的二元运算使用 `&` 和 `|` 运算符，其中 `&` 表示“并且”，`|` 表示“或者”。

例如，要实现题设所给的筛选条件，先分别写出表示“10岁以上”和“50岁以下”的条件，再将其用 `&` 连接。注意连接前每个参与运算的条件需用括号括起来，否则会因为默认的运算符优先级而导致代码逻辑背离我们的期望。

```python
# 注意将查询结果存入变量 midage 中
midage = df.loc[(df['Age'] >= 10) & (df['Age'] < 50), :]
```

所得结果，数据的 `'Age'` 值的分布范围符合我们的预期。

{% asset_img Screenshot_20240719_195622.png %}

> **小记**
> 同样地，若不使用 `loc`，也能如下达到相同的效果：
>
> ```python
> midage = df[(df['Age'] >= 10) & (df['Age'] < 50)]
> ```
